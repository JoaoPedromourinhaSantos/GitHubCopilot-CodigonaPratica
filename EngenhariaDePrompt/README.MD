# ğŸ¤– Engenharia de Prompt (Prompt Engineering)

> **Domine a arte de comunicar com inteligÃªncia artificial. Descubra como formular prompts eficazes para obter as melhores respostas de modelos de linguagem.**

---

Este repositÃ³rio contÃ©m material completo sobre **Engenharia de Prompts**, desde conceitos fundamentais atÃ© tÃ©cnicas avanÃ§adas. Aqui vocÃª encontrarÃ¡ explicaÃ§Ãµes claras sobre prompts, diferenÃ§as entre SLMs e LLMs, estratÃ©gias como few-shot learning, e como usar ferramentas como o GitHub Copilot de forma otimizada.

## ğŸ“š ConteÃºdo

- [O que Ã© um prompt?](#o-que-Ã©-um-prompt)
- [Modelos de Linguagem: SLMs vs LLMs](#llm-slm-e-xlms--qual-a-diferenÃ§a)
- [TÃ©cnicas de Prompting](#tÃ©cnicas-de-prompting)
- [Boas PrÃ¡ticas](#boas-prÃ¡ticas-de-prompt-engineering)
- [GlossÃ¡rio](#glossÃ¡rio-rÃ¡pido)
- [Recursos](#recursos-e-leituras-recomendadas)

### O que Ã© um prompt?

Um prompt Ã© qualquer entrada (texto, instruÃ§Ã£o, contexto, exemplos) enviada a um sistema â€” em especial um modelo de linguagem â€” com o objetivo de guiar sua saÃ­da. Em aplicaÃ§Ãµes com LLMs, o prompt Ã© a principal forma de controlar comportamento, formato e conteÃºdo da resposta.

**Exemplos prÃ¡ticos de prompts:**

```
âŒ Vago: "Resuma o texto"
âœ… Bem definido: "Resuma o artigo em 3 pontos-chave, em linguagem simples, focando em impacto financeiro"

âŒ Falta contexto: "O que Ã© melhor?"
âœ… Com contexto: "Comparando SLMs e LLMs, qual Ã© melhor para aplicaÃ§Ãµes embarcadas com baixa latÃªncia?"

âŒ Sem formato: "Liste ideias"
âœ… Com formato esperado: "Retorne uma lista numerada com 5 ideias de projetos IA, com descriÃ§Ã£o de 1-2 linhas cada"
```

### LLM, SLM e xLMs â€” qual a diferenÃ§a?

Entender os diferentes tipos de modelos ajuda vocÃª a escolher a ferramenta certa para cada tarefa.

#### ğŸ“Š ComparaÃ§Ã£o entre SLMs e LLMs

| CaracterÃ­stica | **SLMs** ğŸƒ | **LLMs** ğŸ¦¾ |
|---|:---:|:---:|
| **NÃºmero de parÃ¢metros** | MilhÃµes a dezenas de milhÃµes | BilhÃµes a trilhÃµes |
| **Dados de treino** | Menores, mais especÃ­ficos | Maiores, variados |
| **Requisitos computacionais** | âœ… Baixos (rÃ¡pido) | âš ï¸ Altos (lento) |
| **CustomizaÃ§Ã£o/Fine-tune** | âœ… FÃ¡cil | âš ï¸ Custoso |
| **Custo operacional** | âœ… Barato | âš ï¸ Caro |
| **EspecializaÃ§Ã£o** | âœ… Excelente em nichos | âœ… Geral, versÃ¡til |
| **Desempenho simples** | âœ… SatisfatÃ³rio | âœ… Excelente |

**ğŸ¯ Quando usar cada um:**

- **SLM**: AplicaÃ§Ãµes embarcadas, dispositivos IoT, requisitos de baixa latÃªncia, domÃ­nios especÃ­ficos (e.g., anÃ¡lise mÃ©dica).
- **LLM**: Tarefas gerais, compreensÃ£o profunda, criatividade, mÃºltiplos domÃ­nios.

**ğŸ’¡ O que Ã© xLMs?** Termo geral que agrupa SLMs, LLMs e outros tipos de modelos. Serve para comparaÃ§Ãµes teÃ³ricas sobre arquitetura, escala e performance.

## ğŸ¯ TÃ©cnicas de Prompting

### De geral a especÃ­fico (tÃ©cnica de prompting)

Uma boa prÃ¡tica de engenharia de prompt Ã© comeÃ§ar com instruÃ§Ãµes simples (geral) e entÃ£o ir refinando atÃ© obter o comportamento esperado (especÃ­fico).

**Exemplo de refinamento iterativo:**

```
IteraÃ§Ã£o 1 (genÃ©rica):
â†’ "Resuma o texto abaixo em 2 frases."

IteraÃ§Ã£o 2 (mais especÃ­fica):
â†’ "Resuma em 2 frases, focando nos impactos financeiros."

IteraÃ§Ã£o 3 (ainda mais especÃ­fica):
â†’ "Resuma em 2 frases, focando nos impactos financeiros e evitando jargÃµes tÃ©cnicos, usando linguagem acessÃ­vel para pÃºblicos leigos."
```

**ğŸ’¡ Dica:** Use essa abordagem incremental para refinar prompts atÃ© atingir exatamente o resultado desejado em formato, tom e detalhe.

---

### Few-shot learning (poucos exemplos)

Few-shot Ã© a tÃ©cnica de incluir **exemplos** de entrada/saÃ­da dentro do prÃ³prio prompt para demonstrar ao modelo o padrÃ£o esperado. Ã‰ especialmente Ãºtil quando vocÃª quer um formato ou comportamento muito especÃ­fico.

**Exemplo prÃ¡tico:**

```
Instruir o modelo com exemplos:

Exemplo 1:
Entrada: "Rome"
SaÃ­da: "Capital: Roma, PaÃ­s: ItÃ¡lia"

Exemplo 2:
Entrada: "Paris"
SaÃ­da: "Capital: Paris, PaÃ­s: FranÃ§a"

Agora faÃ§a o mesmo para:
Entrada: "Madrid"
SaÃ­da:
```

**âœ… Boas prÃ¡ticas:**
- Use 2â€“10 exemplos bem escolhidos (muito exemplos deixa o prompt custoso em tokens)
- Varie exemplos para cobrir casos-limite e padrÃµes diferentes
- Certifique-se que exemplos representam exatamente o que vocÃª espera

---

### Copilot Inline

O GitHub Copilot (e ferramentas similares) usam **prompts inline**: o contexto do seu cÃ³digo, nomes de variÃ¡veis e comentÃ¡rios sÃ£o enviados como parte do prompt para gerar sugestÃµes relevantes diretamente no editor.

**Como aproveitar melhor:**

```java
// âŒ Vago
// escrever funÃ§Ã£o

// âœ… EspecÃ­fico
// Escrever funÃ§Ã£o que valida email usando regex, retorna boolean, lanÃ§a IllegalArgumentException se null
```

**ğŸ’¡ Dicas Copilot:**
- Escreva comentÃ¡rios descritivos antes de funÃ§Ãµes
- Use nomes de variÃ¡veis e mÃ©todos significativos (contexto ajuda!)
- Deixe o histÃ³rico de cÃ³digo visÃ­vel (funÃ§Ãµes anteriores informam o padrÃ£o)
- Seja especÃ­fico sobre entrada, saÃ­da, restriÃ§Ãµes e erros

---

### AI e EstocÃ¡stico â€” o que significa?

**AI (InteligÃªncia Artificial):** Neste contexto, refere-se a modelos de machine learning treinados para processar e gerar linguagem natural de forma inteligente.

**EstocÃ¡stico:** Significa que o modelo pode gerar **saÃ­das diferentes** para o mesmo prompt, dependendo de parÃ¢metros como `temperature` e seed aleatÃ³ria. NÃ£o Ã© determinÃ­stico.

#### Temperature (controle de criatividade)

```
Temperature = 0.1 (conservador):
â†’ "A capital da FranÃ§a Ã© Paris." (sempre a mesma resposta)

Temperature = 0.7 (balanceado):
â†’ Respostas variadas mas coerentes (padrÃ£o para a maioria)

Temperature = 1.5+ (criativo):
â†’ Respostas muito criativas, Ã s vezes irrelevantes
```

**ğŸ¯ Quando usar:**
- **Temp baixa (0.0â€“0.3):** Tarefas precisas (anÃ¡lise, cÃ³digo, dados)
- **Temp mÃ©dia (0.5â€“0.7):** RedaÃ§Ã£o, resumos, criatividade controlada
- **Temp alta (0.8â€“1.0+):** Brainstorm, criatividade, exploraÃ§Ã£o

## âœ… Boas prÃ¡ticas de prompt engineering

Seguindo essas prÃ¡ticas, vocÃª obterÃ¡ respostas de melhor qualidade de qualquer modelo de linguagem:

1. **ğŸ¯ Defina o objetivo claramente**
   - O que exatamente vocÃª espera da saÃ­da?
   - Qual Ã© o contexto e o pÃºblico-alvo?

2. **ğŸ“‹ ForneÃ§a o formato esperado**
   - JSON, CSV, lista numerada, tabela, Markdown?
   - Especifique: "Retorne em formato JSON com chaves: nome, email, telefone"

3. **ğŸš€ Adicione restriÃ§Ãµes e prioridades**
   - Tamanho mÃ¡ximo: "mÃ¡ximo 150 palavras"
   - Tom: "use linguagem tÃ©cnica" ou "use linguagem acessÃ­vel"
   - PÃºblico-alvo: "explicar para um leigo" vs "explicar para especialista"

4. **ğŸ“š Use exemplos (few-shot) quando complexo**
   - Para tarefas com formato nÃ£o-trivial, forneÃ§a 2â€“5 exemplos
   - Exemplos demonstram padrÃ£o melhor que descriÃ§Ã£o textual

5. **ğŸ”„ Teste, itere e meÃ§a**
   - Teste o prompt vÃ¡rias vezes
   - Refine conforme resultado
   - MeÃ§a sucesso: precisÃ£o, relevÃ¢ncia, coerÃªncia, conformidade com formato

**Checklist para um bom prompt:**
- [ ] Objetivo estÃ¡ explÃ­cito?
- [ ] Contexto suficiente fornecido?
- [ ] Formato de saÃ­da especificado?
- [ ] RestriÃ§Ãµes de tamanho, tom, pÃºblico mencionadas?
- [ ] Exemplos inclusos (se necessÃ¡rio)?
- [ ] InstruÃ§Ãµes de error handling (o que fazer se nÃ£o souber a resposta?)

## ğŸ“– GlossÃ¡rio rÃ¡pido

| Termo | DescriÃ§Ã£o |
|---|---|
| **Prompt** | Entrada (texto, instruÃ§Ã£o, contexto) enviada ao modelo para guiar sua saÃ­da |
| **Token** | Unidade bÃ¡sica de texto processada (palavra, subpalavra, sÃ­mbolo â€” nÃ£o Ã© 1:1 com caracteres) |
| **Temperature** | ParÃ¢metro que controla aleatoriedade: baixo = conservador, alto = criativo |
| **Few-shot** | TÃ©cnica de incluir exemplos no prompt para demonstrar padrÃ£o esperado |
| **Fine-tune** | Treinar adicionalmente um modelo prÃ©-treinado com dados especÃ­ficos do usuÃ¡rio |
| **Embedding** | RepresentaÃ§Ã£o numÃ©rica de texto usada internamente pelo modelo |
| **Context window** | Quantidade mÃ¡xima de tokens que o modelo pode "ver" (ex: 4K, 8K, 128K tokens) |
| **LLM** | Large Language Model â€” modelo com bilhÃµes-trilhÃµes de parÃ¢metros |
| **SLM** | Small Language Model â€” modelo com milhÃµes-dezenas de milhÃµes de parÃ¢metros |
| **Chain-of-thought** | TÃ©cnica que instrui o modelo a "pensar passo a passo" para melhor raciocÃ­nio |

## ğŸ“š Recursos e leituras recomendadas

### DocumentaÃ§Ã£o Oficial
- ğŸ”— [GitHub Copilot â€” DocumentaÃ§Ã£o Oficial (PT-BR)](https://docs.github.com/pt/copilot)
- ğŸ”— [OpenAI API Documentation](https://platform.openai.com/docs)
- ğŸ”— [Anthropic Claude Documentation](https://docs.anthropic.com)

### Artigos e Papers
- ğŸ“„ **"Attention Is All You Need"** â€” Vaswani et al. (Arquitetura Transformer, base de LLMs modernos)
- ğŸ“„ **"Chain-of-Thought Prompting"** â€” Wei et al. (TÃ©cnica de raciocÃ­nio passo a passo)
- ğŸ“„ **"Few-shot Learning in Large Language Models"** â€” Brown et al. (GPT-3 paper)

### Tutoriais e Blogs
- ğŸŒ [Prompt Engineering Guide](https://www.promptingguide.ai/) â€” Guia interativo completo
- ğŸŒ [DeepLearning.AI â€” Short Courses](https://www.deeplearning.ai/) â€” Cursos gratuitos sobre prompts
- ğŸŒ [Hugging Face â€” Course](https://huggingface.co/course) â€” Aprender sobre modelos de linguagem

### Ferramentas Ãšteis
- ğŸ› ï¸ **Prompt Testing:** GPT-4, Claude, Gemini (experimentar diferentes prompts)
- ğŸ› ï¸ **AnÃ¡lise:** Ragas, LangChain (avaliar qualidade de respostas)
- ğŸ› ï¸ **Versionamento:** Prompt management tools (Langsmith, Weights & Biases)

---

## ğŸš€ PrÃ³ximos passos

- Explore os projetos dentro deste repositÃ³rio: `Quizz/`, `EncontrarDatas/`, `ImparPar/`
- Experimente tÃ©cnicas de prompting com o GitHub Copilot enquanto programa
- Teste diferentes temperaturas, exemplos (few-shot) e formatos
- MeÃ§a e itere atÃ© atingir qualidade desejada

---

**Ãšltima atualizaÃ§Ã£o:** Dezembro 2025  
**Autor:** JoÃ£o Moura / GitHub Copilot